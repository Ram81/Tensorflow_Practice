{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 12)                84        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 24)                312       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 32)                800       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 12)                300       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 52        \n",
      "=================================================================\n",
      "Total params: 2,340\n",
      "Trainable params: 2,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(12, activation='relu', input_shape=(6,)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(4, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "model=build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4740, 7)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('data/train.csv')\n",
    "from sklearn.utils import resample\n",
    "df_min_1 = df[df.popularity==1]\n",
    "df_min_2 = df[df.popularity==2]\n",
    "df_min_3 = df[df.popularity==3]\n",
    "df_min_4 = df[df.popularity==4]\n",
    "\n",
    "df_min_2 = resample(df_min_2, replace=True, n_samples=1000, random_state=512)\n",
    "df_min_3 = resample(df_min_3, replace=True, n_samples=1000, random_state=512)\n",
    "df_min_4 = resample(df_min_4, replace=True, n_samples=1000, random_state=512)\n",
    "\n",
    "train = pd.concat([df_min_1,df_min_2,df_min_3,df_min_4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X = train.iloc[:, 0:6].values\n",
    "y = train.iloc[:, 6].values\n",
    "# Converting to one hot vectors\n",
    "y = y - 1\n",
    "y = to_categorical(y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rockstar/miniconda3/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3792/3792 [==============================] - 12s - loss: 0.1384 - acc: 0.9877    \n",
      "Epoch 2/30\n",
      "3792/3792 [==============================] - 12s - loss: 0.1337 - acc: 0.9860    \n",
      "Epoch 3/30\n",
      "3792/3792 [==============================] - 11s - loss: 0.1407 - acc: 0.9866    \n",
      "Epoch 4/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1520 - acc: 0.9854    \n",
      "Epoch 5/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1460 - acc: 0.9858    \n",
      "Epoch 6/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1254 - acc: 0.9870    \n",
      "Epoch 7/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1436 - acc: 0.9858    \n",
      "Epoch 8/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1377 - acc: 0.9877    \n",
      "Epoch 9/30\n",
      "3792/3792 [==============================] - 12s - loss: 0.1379 - acc: 0.9867    \n",
      "Epoch 10/30\n",
      "3792/3792 [==============================] - 11s - loss: 0.1481 - acc: 0.9862    \n",
      "Epoch 11/30\n",
      "3792/3792 [==============================] - 11s - loss: 0.1463 - acc: 0.9866    \n",
      "Epoch 12/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1307 - acc: 0.9865    \n",
      "Epoch 13/30\n",
      "3792/3792 [==============================] - 12s - loss: 0.1642 - acc: 0.9861    \n",
      "Epoch 14/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1723 - acc: 0.9836    \n",
      "Epoch 15/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1648 - acc: 0.9850    \n",
      "Epoch 16/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1682 - acc: 0.9854    \n",
      "Epoch 17/30\n",
      "3792/3792 [==============================] - 9s - loss: 0.1501 - acc: 0.9869     \n",
      "Epoch 18/30\n",
      "3792/3792 [==============================] - 9s - loss: 0.1584 - acc: 0.9854     \n",
      "Epoch 19/30\n",
      "3792/3792 [==============================] - 9s - loss: 0.1513 - acc: 0.9851     \n",
      "Epoch 20/30\n",
      "3792/3792 [==============================] - 10s - loss: 0.1601 - acc: 0.9869    \n",
      "Epoch 21/30\n",
      "3792/3792 [==============================] - 11s - loss: 0.1651 - acc: 0.9865    \n",
      "Epoch 22/30\n",
      "3792/3792 [==============================] - 11s - loss: 0.1983 - acc: 0.9844    \n",
      "Epoch 23/30\n",
      "3408/3792 [=========================>....] - ETA: 1s - loss: 0.1513 - acc: 0.9872"
     ]
    }
   ],
   "source": [
    "model.load_weights('weights.h5')\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "score=model.evaluate(X_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "X_test = test.iloc[:, :].values\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = model.predict(X_test)\n",
    "y_test = np.argmax(y_test, axis=1) + 1\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving File\n",
    "result=pd.read_csv('update.csv')\n",
    "result['popularity']=y_test\n",
    "result.head()\n",
    "result.to_csv('prediction.csv', sep=',',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
